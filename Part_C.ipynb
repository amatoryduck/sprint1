{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import argparse\n",
    "    import datetime\n",
    "    import requests\n",
    "    import os\n",
    "    import unicodedata\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import pandas_datareader as pdr\n",
    "    import statsmodels.formula.api as sm\n",
    "    from bs4 import BeautifulSoup\n",
    "    from functools import reduce\n",
    "except:\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Dow\n",
    "\n",
    "This function scrapes the money.cnn.com website for the list of symbols in the Dow Jones Industrial Average. It returns a list of symbols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Dow():\n",
    "    \"\"\"\n",
    "    Get dow uses Beautiful Soup to scrape the money.cnn website\n",
    "    in order to get a list of all the symbols used in the\n",
    "    Dow Jones Industrial Average. This function is only called\n",
    "    if the user passes the '-d' option in the command line.\n",
    "    \"\"\"\n",
    "    Dow_Website = requests.get(\"https://money.cnn.com/data/dow30/\")\n",
    "    soup = BeautifulSoup(Dow_Website.content, \"html.parser\")\n",
    "\n",
    "    Dow_Table = soup.find(\"div\", {\"id\": \"wsod_indexConstituents\"})\n",
    "    rows = Dow_Table.find_all(\"tr\")\n",
    "    Dow_data = list()\n",
    "\n",
    "    for row in rows:\n",
    "        cols = row.find_all(\"td\")\n",
    "        cols = [ele.text.strip() for ele in cols]\n",
    "        Dow_data.append([ele for ele in cols if ele])\n",
    "\n",
    "    Dow_tags = list()\n",
    "    for company in Dow_data:\n",
    "        if company != []:\n",
    "            name = unicodedata.normalize(\"NFKD\", company[0])\n",
    "            tag = name.split(\" \")[0]\n",
    "            Dow_tags.append(tag)\n",
    "\n",
    "    return Dow_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get SP\n",
    "\n",
    "This function scrapes wikipedia for a list of all the symbols in the S&P500. It returns a list of symbols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_SP(): \n",
    "    SP_Website = requests.get(\"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\")\n",
    "    soup = BeautifulSoup(SP_Website.content, \"html.parser\")\n",
    "\n",
    "    SP_Table = soup.find(\"table\", {\"id\": \"constituents\"})\n",
    "    SP_table_body = SP_Table.find('tbody')\n",
    "    rows = SP_table_body.find_all('tr')\n",
    "    rows = rows[1:]\n",
    "    SP_data = list()\n",
    "\n",
    "    for row in rows:\n",
    "        cols = row.find_all('td')\n",
    "        cols = [ele.text.strip() for ele in cols]\n",
    "        SP_data.append([ele for ele in cols if ele])\n",
    "\n",
    "    SP_tags = list()\n",
    "    for company in SP_data:\n",
    "        if company != []:\n",
    "            SP_tags.append(company[0])\n",
    "\n",
    "    return SP_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Commodities\n",
    "\n",
    "This function scrapes yahoo finance for a list of all the commodities symbols. It returns a list of symbols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_commodities():\n",
    "    comm_website = requests.get(\"https://finance.yahoo.com/commodities\")\n",
    "    soup = BeautifulSoup(comm_website.content, \"html.parser\")\n",
    "    commodities = soup.findAll(\"a\", {\"class\":\"Fw(b)\", \"data-symbol\":True})\n",
    "\n",
    "    titles = {}\n",
    "    tickers = []\n",
    "    print(\"Commodities list\")\n",
    "    for commodity in commodities:\n",
    "        ticker = commodity.get(\"data-symbol\")\n",
    "        tickers.append(ticker)\n",
    "        print(ticker)\n",
    "        # Ticker - Title dictionary can be useful later\n",
    "        titles[ticker] = commodity.get(\"title\")\n",
    "\n",
    "    # Hard coded commodities list backup\n",
    "        # Gold, Corn, Crude\n",
    "    commodities = [\"GC=F\", \"C=F\", \"CL=F\"]\n",
    "    \"\"\"if len(tickers) > 0:\n",
    "        return commodities\"\"\"\n",
    "   \t# use following code if you want all tickers\n",
    "    # return tickers \n",
    "    return commodities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Currencies\n",
    "\n",
    "This function scrapes xe.com for a list of all the currency symbols. It returns a list of symbols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_currency():\n",
    "    site = requests.get(\"https://xe.com/symbols.php\")\n",
    "    soup = BeautifulSoup(site.content, \"html.parser\")\n",
    "    table = soup.find(\"table\", {\"class\": \"currencySymblTable\"})\n",
    "    rows = table.find_all(\"tr\")\n",
    "\n",
    "    currency_data = list()\n",
    "    for row in rows:\n",
    "        cols = row.find_all('td')\n",
    "        cols = [ele.text.strip() for ele in cols]\n",
    "        currency_data.append([ele for ele in cols if ele])\n",
    "\n",
    "    currencies = list()\n",
    "    for company in currency_data:\n",
    "        if company != []:\n",
    "            if company[1] != \"Currency Code\":\n",
    "                currencies.append(company[1])\n",
    "\n",
    "    return currencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing command line arguments\n",
    "\n",
    "This program is run through the command line. Before running the program, you should use the command: `chmod a+x external.py`. Then, you should be able to run it with the command `./external.py -s <start date> -e <stop date> [options]`. The option `-h` returns a message explaining the options:\n",
    "```\n",
    "usage: stocks [-h] [-d] [-p] -e END -s START [-m MANUAL] [-q QUICK] [-c] [-o] [-v] [-r]\n",
    "\n",
    "optional arguments:\n",
    "  -h, --help            show this help message and exit\n",
    "  -d, --dow             Select the Dow Jones as your selected stocks\n",
    "  -p, --sp              Select the S&P500 as your selected stocks\n",
    "  -e END, --end END     End date in YYYY-MM-DD format\n",
    "  -s START, --start START\n",
    "                        Start date in YYYY-MM-DD format\n",
    "  -m MANUAL, --manual MANUAL\n",
    "                        Set the stocks you want to watch manually, tickers separated by commas, no whitespace.\n",
    "  -q QUICK, --quick QUICK\n",
    "                        Only get one datapoint instead of all of them.\n",
    "  -c, --currency        Get currency tickers\n",
    "  -o, --commodities     Get commodities tickers\n",
    "  -v, --verbose         Each stock has its own directory\n",
    "  -r, --regress         Return regression csv\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(\"\")\n",
    "except:\n",
    "    parser = argparse.ArgumentParser(\"stocks\")\n",
    "    parser.add_argument(\"-d\", \"--dow\", help=\"Select the Dow Jones as your selected stocks\", default=False, action=\"store_true\")\n",
    "    parser.add_argument(\"-p\", \"--sp\", help=\"Select the S&P500 as your selected stocks\", default=False, action=\"store_true\")\n",
    "    parser.add_argument(\"-e\", \"--end\", help=\"End date in YYYY-MM-DD format\", required=True)\n",
    "    parser.add_argument(\"-s\", \"--start\", help=\"Start date in YYYY-MM-DD format\", required=True)\n",
    "    parser.add_argument(\"-m\", \"--manual\", help=\"Set the stocks you want to watch manually, tickers separated by commas, no whitespace.\", default=\"\")\n",
    "    parser.add_argument(\"-q\", \"--quick\", help=\"Only get one datapoint instead of all of them.\", default=\"\")\n",
    "    parser.add_argument(\"-c\", \"--currency\", help=\"Get currency tickers\", default=False, action=\"store_true\")\n",
    "    parser.add_argument(\"-o\", \"--commodities\", help=\"Get commodities tickers\", default=False, action=\"store_true\")\n",
    "    parser.add_argument(\"-v\", \"--verbose\", help=\"Each stock has its own directory\", default=False, action=\"store_true\")\n",
    "    parser.add_argument(\"-r\", \"--regress\", help=\"Return regression csv\", default=False, action=\"store_true\")\n",
    "\n",
    "    args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sanitization\n",
    "This section of code simply makes sure that the user has given valid options to run this program. Then, it takes all of the requested symbols and puts them into one list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(\"\")\n",
    "except:\n",
    "    try:\n",
    "        start = datetime.datetime.strptime(args.start, \"%Y-%m-%d\")\n",
    "    except:\n",
    "         raise Exception(\"Start date must be in YYYY-MM-DD format\")\n",
    "\n",
    "    try:\n",
    "        end = datetime.datetime.strptime(args.end, \"%Y-%m-%d\")\n",
    "    except:\n",
    "        raise Exception(\"End date must be in YYYY-MM-DD format\")\n",
    "\n",
    "    if not args.dow and not args.sp and args.manual and args.commodities == \"\" and not args.currency:\n",
    "        raise Exception(\"You need to select a market\")\n",
    "\n",
    "    tickers = set()\n",
    "\n",
    "    if args.dow:\n",
    "        tickers = tickers.union(set(get_Dow()))\n",
    "    if args.sp:\n",
    "        tickers = tickers.union(set(get_SP()))\n",
    "    if args.currency:\n",
    "        tickers = tickers.union(set(get_currency()))\n",
    "    if args.commodities:\n",
    "        tickers = tickers.union(set(get_commodities()))\n",
    "    if args.manual != \"\":\n",
    "        tickers = tickers.union(set(args.manual.split(\",\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieving the data\n",
    "This section of code gets stock data requested from yahoo finance and puts it into a pandas database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(\"\")\n",
    "except:\n",
    "    data_list = list()\n",
    "    index = 0\n",
    "    for tag in tickers:\n",
    "        index = index + 1\n",
    "        try:\n",
    "            print(\"Working on : {}, {} OUT OF {}\".format(tag, index, len(tickers)))\n",
    "            if args.quick == \"\":\n",
    "                data = pdr.get_data_yahoo(tag, start=start, end=end)\n",
    "                print(data)\n",
    "                data['Ticker'] = tag\n",
    "                data_list.append(data)\n",
    "            else:\n",
    "                data = pdr.get_data_yahoo(tag, start=start, end=end)\n",
    "                data[\"Ticker\"] = tag\n",
    "                data = data[[ args.quick, \"Ticker\"]]\n",
    "                data_list.append(data)\n",
    "        except:\n",
    "            print(\"DATA NOT FOUND, LIKELY A WEEKEND\")\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verbose mode\n",
    "This code is responsible for handling verbose mode. This will write out all the pandas dataframes we received as csv files as their own directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(\"\")\n",
    "except:\n",
    "    if args.verbose:\n",
    "        table = reduce(lambda x, acc: pd.concat([x, acc]), data_list, pd.DataFrame())\n",
    "        table = table.sort_index()\n",
    "        dates = list(set(table.index.values))\n",
    "\n",
    "        mode = dict()\n",
    "        highs = dict()\n",
    "        lows = dict()\n",
    "        opens = dict()\n",
    "        closes = dict()\n",
    "        volume = dict()\n",
    "        adj_close = dict()\n",
    "        for tag in tickers:\n",
    "            highs[tag] = table[table[\"Ticker\"].str.contains(tag)][\"High\"].values\n",
    "            lows[tag] = table[table[\"Ticker\"].str.contains(tag)][\"Low\"].values\n",
    "            opens[tag] = table[table[\"Ticker\"].str.contains(tag)][\"Open\"].values\n",
    "            closes[tag] = table[table[\"Ticker\"].str.contains(tag)][\"Close\"].values\n",
    "            adj_close[tag] = table[table[\"Ticker\"].str.contains(tag)][\"Adj Close\"].values\n",
    "            volume[tag] = table[table[\"Ticker\"].str.contains(tag)][\"Volume\"].values\n",
    "\n",
    "            if len(highs[tag]) in mode:\n",
    "                mode[len(highs[tag])] = mode[len(highs[tag])] + 1\n",
    "            else:\n",
    "                mode[len(highs[tag])] = 1\n",
    "\n",
    "        tmp = 0\n",
    "        m = 0\n",
    "        for i in mode:\n",
    "            if mode[i] > tmp and i != 0:\n",
    "                tmp = mode[i]\n",
    "                m = i\n",
    "\n",
    "        dicts = [highs, lows, opens, closes, volume, adj_close]\n",
    "        for datapoint in dicts:\n",
    "            datapoint[\"Dates\"] = dates\n",
    "            for tag in datapoint:\n",
    "                l = list()\n",
    "                for x in datapoint[tag]:\n",
    "                    l.append(x)\n",
    "                if len(l) == m:\n",
    "                    datapoint[tag] = l\n",
    "\n",
    "        tmp = dicts\n",
    "        deletes = list()\n",
    "        for i in dicts:\n",
    "            for j in list(i.keys()):\n",
    "                if len(i[j]) != m:\n",
    "                    del i[j]\n",
    "\n",
    "        for i in dicts:\n",
    "            i[\"Dates\"] = dates\n",
    "\n",
    "        l = [\"high\", \"low\", \"open\", \"close\", \"volume\", \"adj_close\"]\n",
    "        i = 0\n",
    "        for datapoint in dicts:\n",
    "            for ticker in datapoint:\n",
    "                try:\n",
    "                    df = pd.DataFrame({ticker: datapoint[ticker]})\n",
    "                    df[\"Dates\"] = dates\n",
    "                    df.set_index(\"Dates\", inplace=True)\n",
    "                    df.sort_index()\n",
    "                    csv = df.to_csv()\n",
    "                    os.system(\"mkdir {}\".format(ticker))\n",
    "                    f = open(\"{}/{}.csv\".format(ticker, l[i]), 'w')\n",
    "                    f.write(csv)\n",
    "                    f.close()\n",
    "                except:\n",
    "                    continue\n",
    "            i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Mode\n",
    "This code is responsible for handling quick mode. Quick mode is when the user only wants to get one datapoint. This will write the requested DataFrames and datapoint in the current directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(\"\")\n",
    "except:\n",
    "    if args.quick == \"\":\n",
    "        table = reduce(lambda x, acc: pd.concat([x, acc]), data_list, pd.DataFrame())\n",
    "        table = table.sort_index()\n",
    "        dates = list(set(table.index.values))\n",
    "\n",
    "        mode = dict()\n",
    "        highs = dict()\n",
    "        lows = dict()\n",
    "        opens = dict()\n",
    "        closes = dict()\n",
    "        volume = dict()\n",
    "        adj_close = dict()\n",
    "        for tag in tickers:\n",
    "            highs[tag] = table[table[\"Ticker\"].str.contains(tag)][\"High\"].values\n",
    "            lows[tag] = table[table[\"Ticker\"].str.contains(tag)][\"Low\"].values\n",
    "            opens[tag] = table[table[\"Ticker\"].str.contains(tag)][\"Open\"].values\n",
    "            closes[tag] = table[table[\"Ticker\"].str.contains(tag)][\"Close\"].values\n",
    "            adj_close[tag] = table[table[\"Ticker\"].str.contains(tag)][\"Adj Close\"].values\n",
    "            volume[tag] = table[table[\"Ticker\"].str.contains(tag)][\"Volume\"].values\n",
    "\n",
    "            if len(highs[tag]) in mode:\n",
    "                mode[len(highs[tag])] = mode[len(highs[tag])] + 1\n",
    "            else:\n",
    "                mode[len(highs[tag])] = 1\n",
    "\n",
    "        tmp = 0\n",
    "        m = 0\n",
    "        for i in mode:\n",
    "            if mode[i] > tmp and i != 0:\n",
    "                tmp = mode[i]\n",
    "                m = i\n",
    "\n",
    "        dicts = [highs, lows, opens, closes, volume, adj_close]\n",
    "        for datapoint in dicts:\n",
    "            datapoint[\"Dates\"] = dates\n",
    "            for tag in datapoint:\n",
    "                l = list()\n",
    "                for x in datapoint[tag]:\n",
    "                    l.append(x)\n",
    "                if len(l) == m:\n",
    "                    datapoint[tag] = l\n",
    "\n",
    "        tmp = dicts\n",
    "        deletes = list()\n",
    "        for i in dicts:\n",
    "            for j in list(i.keys()):\n",
    "                if len(i[j]) != m:\n",
    "                    del i[j]\n",
    "\n",
    "        for i in dicts:\n",
    "            i[\"Dates\"] = dates\n",
    "\n",
    "        highs_frame = pd.DataFrame(highs)\n",
    "        highs_frame.set_index(\"Dates\", inplace=True)\n",
    "        highs_frame.sort_index()\n",
    "        lows_frame = pd.DataFrame(lows)\n",
    "        lows_frame.set_index(\"Dates\", inplace=True)\n",
    "        lows_frame.sort_index()\n",
    "        opens_frame = pd.DataFrame(opens)\n",
    "        opens_frame.set_index(\"Dates\", inplace=True)\n",
    "        opens_frame.sort_index()\n",
    "        closes_frame = pd.DataFrame(closes)\n",
    "        closes_frame.set_index(\"Dates\", inplace=True)\n",
    "        closes_frame.sort_index()\n",
    "        volume_frame = pd.DataFrame(volume)\n",
    "        volume_frame.set_index(\"Dates\", inplace=True)\n",
    "        volume_frame.sort_index()\n",
    "        adj_close_frame = pd.DataFrame(adj_close)\n",
    "        adj_close_frame.set_index(\"Dates\", inplace=True)\n",
    "        adj_close_frame.sort_index()\n",
    "\n",
    "        frames = [highs_frame, lows_frame, opens_frame, closes_frame, volume_frame, adj_close_frame]\n",
    "        i = 0\n",
    "        for name in [\"high\", \"low\", \"open\", \"close\", \"volume\", \"adj_close\"]:\n",
    "            csv = frames[i].to_csv()\n",
    "            f = open(\"{}.csv\".format(name), 'w')\n",
    "            f.write(csv)\n",
    "            f.close()\n",
    "            i = i + 1\n",
    "\n",
    "        i = 0\n",
    "        names = [\"high\", \"low\", \"open\", \"close\", \"volume\", \"adj_close\"]\n",
    "        if args.regress:\n",
    "            for frame in frames:\n",
    "                returns = frame.pct_change()\n",
    "                csv = returns.to_csv()\n",
    "                f = open(\"{}_pct_change.csv\".format(names[i]), 'w')\n",
    "                f.write(csv)\n",
    "                f.close()\n",
    "\n",
    "                line = \" + \".join(frame.columns[1:])\n",
    "                model = sm.ols(\"{} ~ {}\".format(frame.columns[0], line), data=frame)\n",
    "                model = returns.to_csv()\n",
    "                f = open(\"{}_sm.csv\".format(names[i]), 'w')\n",
    "                f.write(csv)\n",
    "                f.close()\n",
    "\n",
    "                i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regular mode\n",
    "This code is responsible for handling the regular mode. It takes all the requested DataFrames and writes them as csvs in the current directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(\"\")\n",
    "except:\n",
    "    table = reduce(lambda x, acc: pd.concat([x, acc]), data_list, pd.DataFrame())\n",
    "    table = table.sort_index()\n",
    "    dates = list(set(table.index.values))\n",
    "\n",
    "    d = dict()\n",
    "    for tag in tickers:\n",
    "        d[tag] = table[table[\"Ticker\"].str.contains(tag)].values\n",
    "\n",
    "    for x in d:\n",
    "        l = list()\n",
    "        for y in d[x]:\n",
    "            l.append(y[0])\n",
    "        d[x] = l\n",
    "    d[\"Dates\"] = dates\n",
    "\n",
    "    df = pd.DataFrame(d)\n",
    "    df.set_index(\"Dates\", inplace=True)\n",
    "    df.sort_index()\n",
    "\n",
    "    csv = df.to_csv()\n",
    "    f = open(\"{}.csv\".format(args.quick), 'w')\n",
    "    f.write(csv)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
