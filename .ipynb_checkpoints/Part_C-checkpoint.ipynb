{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas_datareader'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-4a8800933ca7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas_datareader\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpdr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformula\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mbs4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas_datareader'"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import datetime\n",
    "import requests\n",
    "import os\n",
    "import unicodedata\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_datareader as pdr\n",
    "import statsmodels.formula.api as sm\n",
    "from bs4 import BeautifulSoup\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Dow\n",
    "\n",
    "This function scrapes the money.cnn.com website for the list of symbols in the Dow Jones Industrial Average. It returns a list of symbols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Dow():\n",
    "    Dow_Website = requests.get(\"https://money.cnn.com/data/dow30/\")\n",
    "    soup = BeautifulSoup(Dow_Website.content, \"html.parser\")\n",
    "\n",
    "    Dow_Table = soup.find(\"div\", {\"id\": \"wsod_indexConstituents\"})\n",
    "    rows = Dow_Table.find_all(\"tr\")\n",
    "    Dow_data = list()\n",
    "\n",
    "    for row in rows:\n",
    "        cols = row.find_all(\"td\")\n",
    "        cols = [ele.text.strip() for ele in cols]\n",
    "        Dow_data.append([ele for ele in cols if ele])\n",
    "\n",
    "    Dow_tags = list()\n",
    "    for company in Dow_data:\n",
    "        if company != []:\n",
    "            name = unicodedata.normalize(\"NFKD\", company[0])\n",
    "            tag = name.split(\" \")[0]\n",
    "            Dow_tags.append(tag)\n",
    "\n",
    "    return Dow_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get SP\n",
    "\n",
    "This function scrapes wikipedia for a list of all the symbols in the S&P500. It returns a list of symbols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_SP(): \n",
    "    SP_Website = requests.get(\"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\")\n",
    "    soup = BeautifulSoup(SP_Website.content, \"html.parser\")\n",
    "\n",
    "    SP_Table = soup.find(\"table\", {\"id\": \"constituents\"})\n",
    "    SP_table_body = SP_Table.find('tbody')\n",
    "    rows = SP_table_body.find_all('tr')\n",
    "    rows = rows[1:]\n",
    "    SP_data = list()\n",
    "\n",
    "    for row in rows:\n",
    "        cols = row.find_all('td')\n",
    "        cols = [ele.text.strip() for ele in cols]\n",
    "        SP_data.append([ele for ele in cols if ele])\n",
    "\n",
    "    SP_tags = list()\n",
    "    for company in SP_data:\n",
    "        if company != []:\n",
    "            SP_tags.append(company[0])\n",
    "\n",
    "    return SP_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Commodities\n",
    "\n",
    "This function scrapes yahoo finance for a list of all the commodities symbols. It returns a list of symbols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_commodities():\n",
    "    comm_website = requests.get(\"https://finance.yahoo.com/commodities\")\n",
    "    soup = BeautifulSoup(comm_website.content, \"html.parser\")\n",
    "    commodities = soup.findAll(\"a\", {\"class\":\"Fw(b)\", \"data-symbol\":True})\n",
    "\n",
    "    titles = {}\n",
    "    tickers = []\n",
    "    print(\"Commodities list\")\n",
    "    for commodity in commodities:\n",
    "        ticker = commodity.get(\"data-symbol\")\n",
    "        tickers.append(ticker)\n",
    "        print(ticker)\n",
    "        # Ticker - Title dictionary can be useful later\n",
    "        titles[ticker] = commodity.get(\"title\")\n",
    "\n",
    "    # Hard coded commodities list backup\n",
    "        # Gold, Corn, Crude\n",
    "    commodities = [\"GC=F\", \"C=F\", \"CL=F\"]\n",
    "    \"\"\"if len(tickers) > 0:\n",
    "        return commodities\"\"\"\n",
    "   \t# use following code if you want all tickers\n",
    "    # return tickers \n",
    "    return commodities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Currencies\n",
    "\n",
    "This function scrapes xe.com for a list of all the currency symbols. It returns a list of symbols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_currency():\n",
    "    site = requests.get(\"https://xe.com/symbols.php\")\n",
    "    soup = BeautifulSoup(site.content, \"html.parser\")\n",
    "    table = soup.find(\"table\", {\"class\": \"currencySymblTable\"})\n",
    "    rows = table.find_all(\"tr\")\n",
    "\n",
    "    currency_data = list()\n",
    "    for row in rows:\n",
    "        cols = row.find_all('td')\n",
    "        cols = [ele.text.strip() for ele in cols]\n",
    "        currency_data.append([ele for ele in cols if ele])\n",
    "\n",
    "    currencies = list()\n",
    "    for company in currency_data:\n",
    "        if company != []:\n",
    "            if company[1] != \"Currency Code\":\n",
    "                currencies.append(company[1])\n",
    "\n",
    "    return currencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing command line arguments\n",
    "\n",
    "This program is run through the command line. Before running the program, you should use the command: `chmod a+x external.py`. Then, you should be able to run it with the command `./external.py -s <start date> -e <stop date> [options]`. The option `-h` returns a message explaining the options:\n",
    "```\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: stocks [-h] [-d] [-p] -e END -s START [-m MANUAL] [-q QUICK] [-c] [-o]\n",
      "              [-v] [-r]\n",
      "stocks: error: the following arguments are required: -e/--end, -s/--start\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(\"stocks\")\n",
    "parser.add_argument(\"-d\", \"--dow\", help=\"Select the Dow Jones as your selected stocks\", default=False, action=\"store_true\")\n",
    "parser.add_argument(\"-p\", \"--sp\", help=\"Select the S&P500 as your selected stocks\", default=False, action=\"store_true\")\n",
    "parser.add_argument(\"-e\", \"--end\", help=\"End date in YYYY-MM-DD format\", required=True)\n",
    "parser.add_argument(\"-s\", \"--start\", help=\"Start date in YYYY-MM-DD format\", required=True)\n",
    "parser.add_argument(\"-m\", \"--manual\", help=\"Set the stocks you want to watch manually, tickers separated by commas, no whitespace.\", default=\"\")\n",
    "parser.add_argument(\"-q\", \"--quick\", help=\"Only get one datapoint instead of all of them.\", default=\"\")\n",
    "parser.add_argument(\"-c\", \"--currency\", help=\"Get currency tickers\", default=False, action=\"store_true\")\n",
    "parser.add_argument(\"-o\", \"--commodities\", help=\"Get commodities tickers\", default=False, action=\"store_true\")\n",
    "parser.add_argument(\"-v\", \"--verbose\", help=\"Each stock has its own directory\", default=False, action=\"store_true\")\n",
    "parser.add_argument(\"-r\", \"--regress\", help=\"Return regression csv\", default=False, action=\"store_true\")\n",
    "\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Start date must be in YYYY-MM-DD format",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-a447d979db1e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrptime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"%Y-%m-%d\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'args' is not defined",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-a447d979db1e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrptime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"%Y-%m-%d\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m      \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Start date must be in YYYY-MM-DD format\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: Start date must be in YYYY-MM-DD format"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    start = datetime.datetime.strptime(args.start, \"%Y-%m-%d\")\n",
    "except:\n",
    "     raise Exception(\"Start date must be in YYYY-MM-DD format\")\n",
    "\n",
    "try:\n",
    "    end = datetime.datetime.strptime(args.end, \"%Y-%m-%d\")\n",
    "except:\n",
    "    raise Exception(\"End date must be in YYYY-MM-DD format\")\n",
    "\n",
    "if not args.dow and not args.sp and args.manual and args.commodities == \"\" and not args.currency:\n",
    "    raise Exception(\"You need to select a market\")\n",
    "\n",
    "tickers = set()\n",
    "\n",
    "if args.dow:\n",
    "    tickers = tickers.union(set(get_Dow()))\n",
    "if args.sp:\n",
    "    tickers = tickers.union(set(get_SP()))\n",
    "if args.currency:\n",
    "    tickers = tickers.union(set(get_currency()))\n",
    "if args.commodities:\n",
    "    tickers = tickers.union(set(get_commodities()))\n",
    "if args.manual != \"\":\n",
    "    tickers = tickers.union(set(args.manual.split(\",\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tickers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-196c7137ef14>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdata_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mtag\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtickers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tickers' is not defined"
     ]
    }
   ],
   "source": [
    "data_list = list()\n",
    "index = 0\n",
    "for tag in tickers:\n",
    "    index = index + 1\n",
    "    try:\n",
    "        print(\"Working on : {}, {} OUT OF {}\".format(tag, index, len(tickers)))\n",
    "        if args.quick == \"\":\n",
    "            data = pdr.get_data_yahoo(tag, start=start, end=end)\n",
    "            print(data)\n",
    "            data['Ticker'] = tag\n",
    "            data_list.append(data)\n",
    "        else:\n",
    "            data = pdr.get_data_yahoo(tag, start=start, end=end)\n",
    "            data[\"Ticker\"] = tag\n",
    "            data = data[[ args.quick, \"Ticker\"]]\n",
    "            data_list.append(data)\n",
    "    except:\n",
    "        print(\"DATA NOT FOUND, LIKELY A WEEKEND\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-147a3081e6ec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mtable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mtable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mdates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "if args.verbose:\n",
    "    table = reduce(lambda x, acc: pd.concat([x, acc]), data_list, pd.DataFrame())\n",
    "    table = table.sort_index()\n",
    "    dates = list(set(table.index.values))\n",
    "\n",
    "    mode = dict()\n",
    "    highs = dict()\n",
    "    lows = dict()\n",
    "    opens = dict()\n",
    "    closes = dict()\n",
    "    volume = dict()\n",
    "    adj_close = dict()\n",
    "    for tag in tickers:\n",
    "        highs[tag] = table[table[\"Ticker\"].str.contains(tag)][\"High\"].values\n",
    "        lows[tag] = table[table[\"Ticker\"].str.contains(tag)][\"Low\"].values\n",
    "        opens[tag] = table[table[\"Ticker\"].str.contains(tag)][\"Open\"].values\n",
    "        closes[tag] = table[table[\"Ticker\"].str.contains(tag)][\"Close\"].values\n",
    "        adj_close[tag] = table[table[\"Ticker\"].str.contains(tag)][\"Adj Close\"].values\n",
    "        volume[tag] = table[table[\"Ticker\"].str.contains(tag)][\"Volume\"].values\n",
    "\n",
    "        if len(highs[tag]) in mode:\n",
    "            mode[len(highs[tag])] = mode[len(highs[tag])] + 1\n",
    "        else:\n",
    "            mode[len(highs[tag])] = 1\n",
    "\n",
    "    tmp = 0\n",
    "    m = 0\n",
    "    for i in mode:\n",
    "        if mode[i] > tmp and i != 0:\n",
    "            tmp = mode[i]\n",
    "            m = i\n",
    "\n",
    "    dicts = [highs, lows, opens, closes, volume, adj_close]\n",
    "    for datapoint in dicts:\n",
    "        datapoint[\"Dates\"] = dates\n",
    "        for tag in datapoint:\n",
    "            l = list()\n",
    "            for x in datapoint[tag]:\n",
    "                l.append(x)\n",
    "            if len(l) == m:\n",
    "                datapoint[tag] = l\n",
    "\n",
    "    tmp = dicts\n",
    "    deletes = list()\n",
    "    for i in dicts:\n",
    "        for j in list(i.keys()):\n",
    "            if len(i[j]) != m:\n",
    "                del i[j]\n",
    "\n",
    "    for i in dicts:\n",
    "        i[\"Dates\"] = dates\n",
    "\n",
    "    l = [\"high\", \"low\", \"open\", \"close\", \"volume\", \"adj_close\"]\n",
    "    i = 0\n",
    "    for datapoint in dicts:\n",
    "        for ticker in datapoint:\n",
    "            try:\n",
    "                df = pd.DataFrame({ticker: datapoint[ticker]})\n",
    "                df[\"Dates\"] = dates\n",
    "                df.set_index(\"Dates\", inplace=True)\n",
    "                df.sort_index()\n",
    "                csv = df.to_csv()\n",
    "                os.system(\"mkdir {}\".format(ticker))\n",
    "                f = open(\"{}/{}.csv\".format(ticker, l[i]), 'w')\n",
    "                f.write(csv)\n",
    "                f.close()\n",
    "            except:\n",
    "                continue\n",
    "        i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-13-2b88e32b5038>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-13-2b88e32b5038>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    elif args.quick == \"\":\u001b[0m\n\u001b[1;37m       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "elif args.quick == \"\":\n",
    "    table = reduce(lambda x, acc: pd.concat([x, acc]), data_list, pd.DataFrame())\n",
    "    table = table.sort_index()\n",
    "    dates = list(set(table.index.values))\n",
    "\n",
    "    mode = dict()\n",
    "    highs = dict()\n",
    "    lows = dict()\n",
    "    opens = dict()\n",
    "    closes = dict()\n",
    "    volume = dict()\n",
    "    adj_close = dict()\n",
    "    for tag in tickers:\n",
    "        highs[tag] = table[table[\"Ticker\"].str.contains(tag)][\"High\"].values\n",
    "        lows[tag] = table[table[\"Ticker\"].str.contains(tag)][\"Low\"].values\n",
    "        opens[tag] = table[table[\"Ticker\"].str.contains(tag)][\"Open\"].values\n",
    "        closes[tag] = table[table[\"Ticker\"].str.contains(tag)][\"Close\"].values\n",
    "        adj_close[tag] = table[table[\"Ticker\"].str.contains(tag)][\"Adj Close\"].values\n",
    "        volume[tag] = table[table[\"Ticker\"].str.contains(tag)][\"Volume\"].values\n",
    "\n",
    "        if len(highs[tag]) in mode:\n",
    "            mode[len(highs[tag])] = mode[len(highs[tag])] + 1\n",
    "        else:\n",
    "            mode[len(highs[tag])] = 1\n",
    "\n",
    "    tmp = 0\n",
    "    m = 0\n",
    "    for i in mode:\n",
    "        if mode[i] > tmp and i != 0:\n",
    "            tmp = mode[i]\n",
    "            m = i\n",
    "\n",
    "    dicts = [highs, lows, opens, closes, volume, adj_close]\n",
    "    for datapoint in dicts:\n",
    "        datapoint[\"Dates\"] = dates\n",
    "        for tag in datapoint:\n",
    "            l = list()\n",
    "            for x in datapoint[tag]:\n",
    "                l.append(x)\n",
    "            if len(l) == m:\n",
    "                datapoint[tag] = l\n",
    "\n",
    "    tmp = dicts\n",
    "    deletes = list()\n",
    "    for i in dicts:\n",
    "        for j in list(i.keys()):\n",
    "            if len(i[j]) != m:\n",
    "                del i[j]\n",
    "\n",
    "    for i in dicts:\n",
    "        i[\"Dates\"] = dates\n",
    "\n",
    "    highs_frame = pd.DataFrame(highs)\n",
    "    highs_frame.set_index(\"Dates\", inplace=True)\n",
    "    highs_frame.sort_index()\n",
    "    lows_frame = pd.DataFrame(lows)\n",
    "    lows_frame.set_index(\"Dates\", inplace=True)\n",
    "    lows_frame.sort_index()\n",
    "    opens_frame = pd.DataFrame(opens)\n",
    "    opens_frame.set_index(\"Dates\", inplace=True)\n",
    "    opens_frame.sort_index()\n",
    "    closes_frame = pd.DataFrame(closes)\n",
    "    closes_frame.set_index(\"Dates\", inplace=True)\n",
    "    closes_frame.sort_index()\n",
    "    volume_frame = pd.DataFrame(volume)\n",
    "    volume_frame.set_index(\"Dates\", inplace=True)\n",
    "    volume_frame.sort_index()\n",
    "    adj_close_frame = pd.DataFrame(adj_close)\n",
    "    adj_close_frame.set_index(\"Dates\", inplace=True)\n",
    "    adj_close_frame.sort_index()\n",
    "\n",
    "    frames = [highs_frame, lows_frame, opens_frame, closes_frame, volume_frame, adj_close_frame]\n",
    "    i = 0\n",
    "    for name in [\"high\", \"low\", \"open\", \"close\", \"volume\", \"adj_close\"]:\n",
    "        csv = frames[i].to_csv()\n",
    "        f = open(\"{}.csv\".format(name), 'w')\n",
    "        f.write(csv)\n",
    "        f.close()\n",
    "        i = i + 1\n",
    "\n",
    "    i = 0\n",
    "    names = [\"high\", \"low\", \"open\", \"close\", \"volume\", \"adj_close\"]\n",
    "    if args.regress:\n",
    "        for frame in frames:\n",
    "            returns = frame.pct_change()\n",
    "            csv = returns.to_csv()\n",
    "            f = open(\"{}_pct_change.csv\".format(names[i]), 'w')\n",
    "            f.write(csv)\n",
    "            f.close()\n",
    "\n",
    "            line = \" + \".join(frame.columns[1:])\n",
    "            model = sm.ols(\"{} ~ {}\".format(frame.columns[0], line), data=frame)\n",
    "            model = returns.to_csv()\n",
    "            f = open(\"{}_sm.csv\".format(names[i]), 'w')\n",
    "            f.write(csv)\n",
    "            f.close()\n",
    "\n",
    "            i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "else:\n",
    "    table = reduce(lambda x, acc: pd.concat([x, acc]), data_list, pd.DataFrame())\n",
    "    table = table.sort_index()\n",
    "    dates = list(set(table.index.values))\n",
    "\n",
    "    d = dict()\n",
    "    for tag in tickers:\n",
    "        d[tag] = table[table[\"Ticker\"].str.contains(tag)].values\n",
    "\n",
    "    for x in d:\n",
    "        l = list()\n",
    "        for y in d[x]:\n",
    "            l.append(y[0])\n",
    "        d[x] = l\n",
    "    d[\"Dates\"] = dates\n",
    "\n",
    "    df = pd.DataFrame(d)\n",
    "    df.set_index(\"Dates\", inplace=True)\n",
    "    df.sort_index()\n",
    "\n",
    "    csv = df.to_csv()\n",
    "    f = open(\"{}.csv\".format(args.quick), 'w')\n",
    "    f.write(csv)\n",
    "    f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
